{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n",
        "<font size=\"5px\" color=\"white\">\n",
        "<hr style=\"color: red;\">\n",
        "Creating a simple persian chatbot with open-source LLMs using Python and Hugging Face\n",
        "<hr style=\"color: red;\">\n",
        "</font>\n",
        "<font size=\"4px\" color=\"black\">\n",
        "A chatbot is a computer program that takes a text input, and returns a corresponding text output.\n",
        "\n",
        "Chatbots use a special kind of computer program called a transformer, which is like its brain. Inside this brain, there is something called a language model (LLM), which helps the chatbot understand and generate human-like responses. It looks at lots of examples of human conversations it has seen before to help it respond in a way that makes sense.\n",
        "</font>\n",
        "</div>"
      ],
      "metadata": {
        "id": "WhrkmBNPvCDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Installing Requirements**"
      ],
      "metadata": {
        "id": "BqndYxP9v8MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "PEXQQm8juq3Z"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Import our required tools from the transformers library**"
      ],
      "metadata": {
        "id": "BQvMBffTwOo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BlenderbotForConditionalGeneration"
      ],
      "metadata": {
        "id": "bkb38q_uwX8t"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3- Choosing a model**"
      ],
      "metadata": {
        "id": "y_PfYxHlwm5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n",
        "<hr style=\"color: red;\">\n",
        "<font size=\"4px\" color=\"black\">\n",
        "A chatbot is a computer program that takes a text input, and returns a corresponding text output.\n",
        "\n",
        "Chatbots use a special kind of computer program called a transformer, which is like its brain. Inside this brain, there is something called a language model (LLM), which helps the chatbot understand and generate human-like responses. It looks at lots of examples of human conversations it has seen before to help it respond in a way that makes sense.\n",
        "For this example, we'll be using \"facebook/blenderbot-400M-distill\" because it has an open-source license and runs relatively fast.\n",
        "</font>\n",
        "<hr style=\"color: red;\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "CRd_uLodw_TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/blenderbot-400M-distill\""
      ],
      "metadata": {
        "id": "YjDq8NUMxaKF"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- Fetch the model and initialize a tokenizer**"
      ],
      "metadata": {
        "id": "56SWNhgBwn1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model (download on first run and reference local installation for consequent runs)\n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "7jUBIP_GxjPm"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5- Chat**"
      ],
      "metadata": {
        "id": "uc2hJv24wovV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-1- Fetch prompt from user**"
      ],
      "metadata": {
        "id": "aK4_tfrHyLRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall googletrans -y\n",
        "!pip install googletrans==4.0.0rc1"
      ],
      "metadata": {
        "id": "Dzy7Kbax6nRr"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "\n",
        "print(googletrans.__version__)\n",
        "print(googletrans.LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G41QYL796xfp",
        "outputId": "a3b45b98-c819-42a1-8caf-c1ed5218fc3c"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0-rc.1\n",
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "translator = Translator()"
      ],
      "metadata": {
        "id": "CZh5rWfh69O4"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"هوش مصنوعی چیست\"\n",
        "input_text = translator.translate(input_text, dest='en')\n",
        "input_text = input_text.text\n",
        "input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IYnyFYvf7Akm",
        "outputId": "6c66dc4b-ac90-4f01-9e0b-bfcc9dca8529"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is artificial intelligence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-2- Tokenization of User Prompt and Chat History**"
      ],
      "metadata": {
        "id": "RmHa_jnX8MmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer([input_text], return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt63NCma8L3g",
        "outputId": "a15cd1e4-2766-4989-894a-a6c6be1d117b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 714,  315, 1428, 1233,  725, 7119,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-3- Generate output from model**"
      ],
      "metadata": {
        "id": "ln8_CfqP9EGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnP0TI979Itm",
        "outputId": "32182f65-5e42-4431-dc42-3750f178c9de"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   1,  452,  315,  271, 4769,  306, 1958,  650,   90,  298,  544,  382,\n",
              "          366, 1115,  287, 2282, 1452,  264, 7614,   21,    2]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-4- Decode output**"
      ],
      "metadata": {
        "id": "6GIiDGLr9TIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "print(response)\n",
        "response = translator.translate(response, src='auto', dest='fa')\n",
        "response = response.text\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry3gMFdp9XWz",
        "outputId": "82de18a1-de7f-4fad-9c4e-b28a585a5faa"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It is the study of human beings and how they are able to perform certain tasks.\n",
            "این مطالعه انسان ها و چگونگی قادر به انجام کارهای خاص است.\n"
          ]
        }
      ]
    }
  ]
}